{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.stats import beta\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sns.set_theme(\"paper\", \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv(\"./DSock/Active_Users.csv\", index_col=0)\n",
    "print(df_users.shape)\n",
    "display(df_users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evals = pd.read_csv(\"./DSock/human_eval_analysis/attitude_tracking.csv\")\n",
    "\n",
    "df_evals = pd.merge(df_users, df_evals, how=\"left\", left_on=\"MTurk_ID\", right_on=\"id\").rename({\"id_x\": \"id\"}, axis=1)\n",
    "\n",
    "df_evals.index = [f\"u{u}\" for u in df_evals[\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = list(\"abcdefgh\")\n",
    "deltas = [\"10\", \"21\", \"32\", \"43\", \"54\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = pd.date_range(\"2020-09-03-03:59:59\", periods=6, tz=\"utc\")\n",
    "\n",
    "get_change = lambda u, t: df_evals.loc[u][[f\"{t}_delta_{d}\" for d in deltas]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_change = {\n",
    "    u: {t: (np.array(get_change(u, t)) != 0).sum() for t in topics}\n",
    "    for u in df_evals.index\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get events\n",
    "\n",
    "+ post events -> nodes\n",
    "+ comment events -> nodes\n",
    "+ view events -> edges\n",
    "+ like events -> edges\n",
    "+ report events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts = pd.read_csv(\"./DSock/direct_influence/posts_with_senti_and_topic.csv\", parse_dates=[\"createdAt\"])\n",
    "df_comts = pd.read_csv(\"./DSock/direct_influence/comments_with_senti_and_topic.csv\", delimiter=\",\", parse_dates=[\"createdAt\"]).dropna(subset=[\"CommenterId\", \"PostId\"])\n",
    "df_views = pd.read_csv(\"./DSock/postViews.csv\", delimiter=\"|\", parse_dates=[\"createdAt\"]).dropna(subset=[\"UserId\", \"PostId\"])\n",
    "df_likes = pd.read_csv(\"./DSock/Likes.csv\", delimiter=\"|\", parse_dates=[\"createdAt\"]).dropna(subset=[\"UserId\", \"PostId\"])\n",
    "df_repts = pd.read_csv(\"./DSock/ReportUsers.csv\", delimiter=\"|\", parse_dates=[\"createdAt\"])\n",
    "\n",
    "print(f\"posts: {df_posts.shape}, comments: {df_comts.shape}, views: {df_views.shape}, likes: {df_likes.shape}, reports: {df_repts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_likes[\"UserId\"] = df_likes[\"UserId\"].astype(int)\n",
    "df_likes[\"PostId\"] = df_likes[\"PostId\"].astype(int)\n",
    "\n",
    "df_comts[\"CommenterId\"] = df_comts[\"CommenterId\"].astype(int)\n",
    "df_comts[\"PostId\"] = df_comts[\"PostId\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create auxiliary graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for u, uname, obsr, sock in df_users[[\"id\", \"username\", \"isObserver\", \"isPuppet\"]].values:\n",
    "    G.add_node(f\"u{u}\", id=u, kind=\"user\", name=uname, observer=(obsr == \"t\"), sock=(sock == \"t\"))\n",
    "    if obsr == \"t\":\n",
    "        G.nodes[f\"u{u}\"][\"color\"] = \"obsr\"\n",
    "    elif sock == \"t\":\n",
    "        G.nodes[f\"u{u}\"][\"color\"] = \"sock\"\n",
    "    else:\n",
    "        G.nodes[f\"u{u}\"][\"color\"] = \"part\"\n",
    "\n",
    "for p, author, t, senti, score, topic in df_posts[[\"PostID\", \"AuthorId\", \"createdAt\", \"labels\", \"scores\", \"topic_label\"]].values:\n",
    "    G.add_node(f\"p{p}\", id=p, kind=\"post\", time=t, user=author, senti=senti, score=score, topic=topic)\n",
    "\n",
    "for c, author, t, senti, score, topic in df_comts[[\"id\", \"CommenterId\", \"createdAt\", \"labels\", \"scores\", \"topic_label\"]].values:\n",
    "    G.add_node(f\"c{c}\", id=c, kind=\"comt\", time=t, user=author, senti=senti, score=score, topic=topic)\n",
    "\n",
    "for l, u, p, t in df_likes[[\"id\", \"UserId\", \"PostId\", \"createdAt\"]].values:\n",
    "    p_name = f\"p{p}\" if p in df_posts[\"PostID\"] else f\"c{p}\"\n",
    "    if f\"u{u}\" in G.nodes and p_name in G.nodes:\n",
    "        G.add_node(f\"l{l}\", user=u, post=p_name, time=t, id=l, kind=\"like\",\n",
    "                   topic=G.nodes[p_name][\"topic\"], senti=\"like\", score=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add views\n",
    "for u, p, t, i in df_views[[\"UserId\", \"PostId\", \"createdAt\", \"id\"]].values:\n",
    "    p_name = f\"p{p}\" if p in df_posts[\"PostID\"] else f\"c{p}\"\n",
    "    if f\"u{u}\" in G.nodes and p_name in G.nodes:\n",
    "        G.add_edge(f\"u{u}\", p_name, time=t, id=i, kind=\"view\")\n",
    "\n",
    "# add likes\n",
    "# for u, p, t, i in df_likes[[\"UserId\", \"PostId\", \"createdAt\", \"id\"]].values:\n",
    "#     p_name = f\"p{p}\" if p in df_posts[\"PostID\"] else f\"c{p}\"\n",
    "#     if f\"u{u}\" in G.nodes and p_name in G.nodes:\n",
    "#         G.add_edge(f\"u{u}\", p_name, time=t, id=i, kind=\"like\")\n",
    "for l, u, p, t in df_likes[[\"id\", \"UserId\", \"PostId\", \"createdAt\"]].values:\n",
    "    p_name = f\"p{p}\" if p in df_posts[\"PostID\"] else f\"c{p}\"\n",
    "    if f\"u{u}\" in G.nodes and p_name in G.nodes:\n",
    "        G.add_edge(f\"u{u}\", f\"l{l}\", user=u, post=p_name, time=t, id=l, kind=\"like\")\n",
    "        G.add_edge(f\"l{l}\", p_name, user=u, post=p_name, time=t, id=l, kind=\"like\")\n",
    "\n",
    "# add create\n",
    "for p, u, t in df_posts[[\"PostID\", \"AuthorId\", \"createdAt\"]].values:\n",
    "    if f\"u{u}\" in G.nodes:\n",
    "        G.add_edge(f\"p{p}\", f\"u{u}\", time=t, kind=\"make\")\n",
    "\n",
    "for c, u, t, in df_comts[[\"id\", \"CommenterId\", \"createdAt\"]].values:\n",
    "    if f\"u{u}\" in G.nodes:\n",
    "        G.add_edge(f\"c{c}\", f\"u{u}\", time=t, kind=\"make\")\n",
    "\n",
    "# for c, u, t in df_comts[[\"PostId\", \"CommenterId\", \"createdAt\"]].values:\n",
    "#     if f\"u{u}\" in G.nodes and f\"c{c}\" in G.nodes:\n",
    "#         G.add_edge(f\"c{c}\", f\"u{u}\", kind=\"comt_by\", time=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subgraph_with_node(G, node_name, topic=\"a\"):\n",
    "    # children = nx.descendants(G, source=node_name) | {node_name}\n",
    "    tree = {\n",
    "        e[1]: {\n",
    "            \"node\": G.nodes[e[1]],\n",
    "            \"edge\": G.edges[e],\n",
    "            \"time\": G.edges[e][\"time\"],\n",
    "        }\n",
    "        # filter with topic\n",
    "        for e in G.out_edges(node_name) if G.nodes[e[1]][\"topic\"] == topic\n",
    "    }\n",
    "\n",
    "    path = sorted(tree, key=lambda x: tree[x][\"time\"])\n",
    "    \n",
    "    return tree, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_name = \"u2337\"\n",
    "topic = \"a\"\n",
    "\n",
    "tree, path = get_subgraph_with_node(G, node_name, topic)\n",
    "\n",
    "print(len(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define colors and styles for graph drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_color = sns.color_palette(\"tab10\")\n",
    "use_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_map = {\n",
    "    \"view\": \"-\",\n",
    "    \"like\": \".\",\n",
    "}\n",
    "\n",
    "color_map = {\n",
    "    \"view\": 4,\n",
    "    \"like\": 1,\n",
    "    \n",
    "    \"part\": 2,\n",
    "    \"sock\": 3,\n",
    "    \"obsr\": 7,\n",
    "    \n",
    "    \"make\": 5,\n",
    "    \"comt\": 9,\n",
    "    \"post\": 0,\n",
    "    \n",
    "    \"user\": 8,\n",
    "}\n",
    "\n",
    "style_map = {\n",
    "    \"post\": \"o\",\n",
    "    \"comt\": \"s\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subG = nx.subgraph(G, path + [node_name])\n",
    "\n",
    "pos = nx.spring_layout(subG, seed=3)\n",
    "# pos = nx.drawing.nx_agraph.graphviz_layout(subG, prog=\"dot\")\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.subplots()\n",
    "\n",
    "nx.draw(\n",
    "    subG, ax=ax,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "    node_color=[use_color[color_map[subG.nodes[n][\"kind\"]]]\n",
    "                if n[0] != \"u\" else use_color[color_map[subG.nodes[n][\"color\"]]]\n",
    "                for n in subG.nodes],\n",
    "    edge_color=[use_color[color_map[subG.edges[e][\"kind\"]]] for e in subG.edges],\n",
    "    labels={n: f\"{n}\\n{subG.nodes[n]['senti']}\" if subG.nodes[n]['kind'] != \"user\" else n for n in subG.nodes},\n",
    "    font_size=10,\n",
    ")\n",
    "\n",
    "nx.draw_networkx_edge_labels(\n",
    "    subG, pos=pos, ax=ax,\n",
    "    edge_labels={e: f\"{subG.edges[e]['time']:%d-%H:%M}\" for e in subG.edges}\n",
    ")\n",
    "\n",
    "# ax.set_title(f\"Auxilary graph\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_timeline = {\n",
    "    f\"{node_name}_{i}\": {\n",
    "        \"node\": G.nodes[node_name],\n",
    "        \"time\": timeline[i],\n",
    "        \"change\": get_change(node_name, topic)[i-1] if i > 0 else 0,\n",
    "    } for i in range(6)\n",
    "}\n",
    "\n",
    "print(user_timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_full = {**tree, **user_timeline}\n",
    "path_full = sorted(path + list(user_timeline.keys()), key=lambda x: tree_full[x][\"time\"])\n",
    "\n",
    "pathG = nx.DiGraph()\n",
    "\n",
    "pathG.add_nodes_from(path_full)\n",
    "\n",
    "for i in range(len(path_full)):\n",
    "    for j in range(i+1, len(path_full)):\n",
    "        x = path_full[i]\n",
    "        y = path_full[j]\n",
    "        if y[0] == \"u\" and x[0] != \"u\":\n",
    "            pathG.add_edge(y, x, **G.edges[(y[:-2], x)])\n",
    "            break\n",
    "\n",
    "nx.set_node_attributes(\n",
    "    pathG,\n",
    "    {\n",
    "        n: {\n",
    "           \"color\": use_color[color_map[tree_full[n][\"node\"][\"kind\"]]],\n",
    "        }\n",
    "        for n in pathG.nodes\n",
    "    }\n",
    ")\n",
    "\n",
    "nx.set_edge_attributes(\n",
    "    pathG,\n",
    "    {\n",
    "        e: {\"color\": use_color[color_map[pathG.edges[e][\"kind\"]]]}\n",
    "        for e in pathG.edges\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = {}\n",
    "for n in pathG.nodes:\n",
    "    pos[n] = np.array([len(pos), 0])\n",
    "\n",
    "fig = plt.figure(figsize=(14, 4))\n",
    "ax = fig.subplots()\n",
    "\n",
    "nx.draw(\n",
    "    pathG,\n",
    "    pos=pos,\n",
    "    ax=ax,\n",
    "    with_labels=True,\n",
    "    font_size=10,\n",
    "    node_color=[pathG.nodes[n][\"color\"] for n in pathG.nodes],\n",
    "    edge_color=[pathG.edges[e][\"color\"] for e in pathG.edges],\n",
    "    labels={n: f\"{n}\" if n[0]!=\"u\" else f\"{n}\\n{tree_full[n]['change']}\" for n in pathG.nodes},\n",
    "    connectionstyle=\"arc3,rad=2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full influence graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_name = \"u2337\"\n",
    "topic = \"a\"\n",
    "\n",
    "descend_full = [n for n in nx.descendants(G, node_name)\n",
    "                if n[0] == \"u\" or G.nodes[n][\"topic\"] == topic]\n",
    "\n",
    "np.random.seed(4)\n",
    "# descend_full = np.random.choice(descend_full, 65, replace=False).tolist()\n",
    "\n",
    "subG = G.subgraph(descend_full + [node_name]).copy()\n",
    "print(len(subG))\n",
    "\n",
    "subG = subG.subgraph([n for n in subG if nx.has_path(subG, node_name, n)])\n",
    "print(len(subG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.spring_layout(subG, iterations=6, seed=3)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.subplots()\n",
    "\n",
    "nx.draw(\n",
    "    subG, ax=ax,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "    node_color=[use_color[color_map[subG.nodes[n][\"kind\"]]] for n in subG.nodes],\n",
    "    edge_color=[use_color[color_map[subG.edges[e][\"kind\"]]] for e in subG.edges],\n",
    "    labels={n: f\"{n}\\n{subG.nodes[n]['senti']}\" if subG.nodes[n]['kind'] != \"user\" else n for n in subG.nodes},\n",
    "    font_size=10,\n",
    ")\n",
    "\n",
    "# nx.draw_networkx_edge_labels(\n",
    "#     subG, pos=pos, ax=ax,\n",
    "#     edge_labels={e: f\"{subG.edges[e]['time']:%d-%H:%M}\" for e in subG.edges},\n",
    "#     font_size=8,\n",
    "# )\n",
    "\n",
    "print(len(subG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = nx.spring_layout(subG, iterations=100)\n",
    "pos = nx.drawing.nx_agraph.graphviz_layout(subG, prog=\"dot\")\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.subplots()\n",
    "\n",
    "nx.draw(\n",
    "    subG, ax=ax,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "#     node_color=[use_color[color_map[subG.nodes[n][\"kind\"]]] for n in subG.nodes],\n",
    "    node_color=[use_color[color_map[subG.nodes[n][\"kind\"]]]\n",
    "                if n[0] != \"u\" else use_color[color_map[subG.nodes[n][\"color\"]]]\n",
    "                for n in subG.nodes],\n",
    "    edge_color=[use_color[color_map[subG.edges[e][\"kind\"]]] for e in subG.edges],\n",
    "    labels={n: f\"{n}\\n{subG.nodes[n]['senti']}\" if subG.nodes[n]['kind'] != \"user\" else n for n in subG.nodes},\n",
    "    font_size=10,\n",
    ")\n",
    "\n",
    "nx.draw_networkx_edge_labels(\n",
    "    subG, pos=pos, ax=ax,\n",
    "    edge_labels={e: f\"{subG.edges[e]['time']:%d-%H:%M}\" for e in subG.edges},\n",
    "    font_size=8,\n",
    ")\n",
    "\n",
    "print(len(subG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_window = pd.Timedelta(\"1 day\")\n",
    "moment_time = timeline[5]\n",
    "topic = \"a\"\n",
    "pr_alpha = 0.85\n",
    "beta_rv = beta(a=0.5, b=0.5)\n",
    "\n",
    "node_name = \"u2337\"\n",
    "\n",
    "print(f\"{attention_window}, {moment_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment_nodes = [n for n in G if n[0] == \"u\" or G.nodes[n][\"topic\"] == topic]\n",
    "\n",
    "moment_graph = G.subgraph(moment_nodes).copy()\n",
    "print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "\n",
    "# remove edges outside attention window\n",
    "remove_edges = [e for e in moment_graph.edges if moment_graph.edges[e][\"time\"] > moment_time]\n",
    "for n in moment_graph:\n",
    "    if n[0] == \"u\" and not G.nodes[n][\"observer\"] and len(moment_graph.in_edges(n)) > 0:\n",
    "        t_min = min([G.edges[e][\"time\"] for e in moment_graph.in_edges(n)])\n",
    "        t_max = max([G.edges[e][\"time\"] for e in moment_graph.in_edges(n)])\n",
    "        remove_edges += [e for e in moment_graph.out_edges(n) if not t_min - attention_window < moment_graph.edges[e][\"time\"] <= t_max]\n",
    "\n",
    "print(f\"remove edges {len(remove_edges)}\")\n",
    "moment_graph.remove_edges_from(remove_edges)\n",
    "print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "\n",
    "# for source node node_name only\n",
    "descend_full = [n for n in nx.descendants(moment_graph, node_name)]\n",
    "moment_graph = moment_graph.subgraph(descend_full + [node_name]).copy()\n",
    "print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "moment_graph = moment_graph.subgraph([n for n in moment_graph if nx.has_path(moment_graph, node_name, n)]).copy()\n",
    "print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "\n",
    "# remove isolated nodes\n",
    "isolates = list(nx.isolates(moment_graph))\n",
    "moment_graph.remove_nodes_from(isolates)\n",
    "print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "\n",
    "\n",
    "for node in moment_graph:\n",
    "    elist = sorted(moment_graph.out_edges(node), key=lambda e: G.edges[e][\"time\"])\n",
    "    x = np.linspace(0, 1, len(elist)+2)[1:-1]\n",
    "    y = beta_rv.pdf(x)\n",
    "    y = y / y.sum()\n",
    "    for e, w in zip(elist, y):\n",
    "        moment_graph.edges[e][\"weight\"] = w\n",
    "\n",
    "pr_value = nx.pagerank_numpy(moment_graph, alpha=pr_alpha, weight=\"weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = nx.drawing.nx_agraph.graphviz_layout(moment_graph, prog=\"dot\")\n",
    "pos = nx.drawing.nx_agraph.graphviz_layout(moment_graph)\n",
    "# pos = nx.spring_layout(moment_graph, iterations=3, seed=3)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "ax = fig.subplots()\n",
    "\n",
    "nx.draw(\n",
    "    moment_graph, ax=ax,\n",
    "    pos=pos,\n",
    "    with_labels=True,\n",
    "#     node_color=[use_color[color_map[moment_graph.nodes[n][\"kind\"]]] for n in moment_graph.nodes],\n",
    "    node_color=[use_color[color_map[moment_graph.nodes[n][\"kind\"]]]\n",
    "                if n[0] != \"u\" else use_color[color_map[moment_graph.nodes[n][\"color\"]]]\n",
    "                for n in moment_graph.nodes],\n",
    "    edge_color=[use_color[color_map[moment_graph.edges[e][\"kind\"]]] for e in moment_graph.edges],\n",
    "    labels={n: f\"{n}\\n{moment_graph.nodes[n]['senti']}\" if moment_graph.nodes[n]['kind'] != \"user\" else n for n in moment_graph.nodes},\n",
    "    font_size=10,\n",
    "    node_size=[pr_value[n]*len(moment_graph)*100 for n in moment_graph],\n",
    ")\n",
    "\n",
    "nx.draw_networkx_edge_labels(\n",
    "    subG, pos=pos, ax=ax,\n",
    "#     edge_labels={e: f\"{moment_graph.edges[e]['time']:%d-%H:%M}\" for e in moment_graph.edges},\n",
    "    edge_labels={e: \"\" for e in moment_graph.edges},\n",
    "    font_size=8,\n",
    ")\n",
    "\n",
    "print(len(moment_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pagerank(G, node_name, pr_alpha, beta_a, beta_b, moment_time, attention_window, topic=None):\n",
    "    if topic == None:\n",
    "        moment_nodes = G.nodes\n",
    "    else:\n",
    "        moment_nodes = [n for n in G if n[0] == \"u\" or G.nodes[n][\"topic\"] == topic]\n",
    "\n",
    "    moment_graph = G.subgraph(moment_nodes).copy()\n",
    "    print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "\n",
    "    # remove edges outside attention window\n",
    "    remove_edges = [e for e in moment_graph.edges if moment_graph.edges[e][\"time\"] > moment_time]\n",
    "    for n in moment_graph:\n",
    "        if n[0] == \"u\" and not G.nodes[n][\"observer\"] and len(moment_graph.in_edges(n)) > 0:\n",
    "            t_min = min([G.edges[e][\"time\"] for e in moment_graph.in_edges(n)])\n",
    "            t_max = max([G.edges[e][\"time\"] for e in moment_graph.in_edges(n)])\n",
    "            remove_edges += [e for e in moment_graph.out_edges(n) if not t_min - attention_window < moment_graph.edges[e][\"time\"] <= t_max]\n",
    "\n",
    "#     print(f\"remove edges {len(remove_edges)}\")\n",
    "    moment_graph.remove_edges_from(remove_edges)\n",
    "#     print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "\n",
    "    # for source node node_name only\n",
    "    descend_full = [n for n in nx.descendants(moment_graph, node_name)]\n",
    "    moment_graph = moment_graph.subgraph(descend_full + [node_name]).copy()\n",
    "#     print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "    moment_graph = moment_graph.subgraph([n for n in moment_graph if nx.has_path(moment_graph, node_name, n)]).copy()\n",
    "#     print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "\n",
    "    # remove isolated nodes\n",
    "    isolates = list(nx.isolates(moment_graph))\n",
    "    moment_graph.remove_nodes_from(isolates)\n",
    "    print(f\"nodes {len(moment_graph)}, edges: {len(moment_graph.edges)}\")\n",
    "\n",
    "\n",
    "    for node in moment_graph:\n",
    "        elist = sorted(moment_graph.out_edges(node), key=lambda e: G.edges[e][\"time\"])\n",
    "        x = np.linspace(0, 1, len(elist)+2)[1:-1]\n",
    "        y = beta_rv.pdf(x)\n",
    "        y = y / y.sum()\n",
    "        for e, w in zip(elist, y):\n",
    "            moment_graph.edges[e][\"weight\"] = w\n",
    "\n",
    "    pr_value = nx.pagerank_numpy(moment_graph, alpha=pr_alpha, weight=\"weight\")\n",
    "    return pr_value, moment_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_window = pd.Timedelta(\"1 day\")\n",
    "moment_time = timeline[5]\n",
    "topic = \"a\"\n",
    "pr_alpha = 0.85\n",
    "beta_rv = beta(a=0.5, b=0.5)\n",
    "\n",
    "node_name = \"u2337\"\n",
    "\n",
    "pr_value, moment_graph = compute_pagerank(G, node_name=node_name, pr_alpha=pr_alpha, beta_a=0.5, beta_b=0.5, moment_time=moment_time, attention_window=attention_window, topic=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsr_list = [f\"u{u}\" for u in df_users[df_users[\"isObserver\"] == \"t\"][\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "# from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyq = [(node_name, t, pr_alpha, beta_a, beta_b)\n",
    "    for node_name in obsr_list for t in timeline[1:]\n",
    "    for pr_alpha, beta_a, beta_b in itertools.product(np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5), np.linspace(0.1, 0.9, 5))\n",
    "       ]\n",
    "\n",
    "print(f\"jobs: {len(keyq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_compute_pagerank(n, p, a, b, t):\n",
    "    return compute_pagerank(\n",
    "    G, node_name=n, pr_alpha=p, beta_a=a, beta_b=b, moment_time=t, attention_window=attention_window, topic=None)\n",
    "\n",
    "pr_dict_fp = Path(\"res/pr_dict.pkl\")\n",
    "\n",
    "if pr_dict_fp.exists():\n",
    "    print(\"load from file\")\n",
    "    with open(pr_dict_fp, \"rb\") as fp:\n",
    "        pr_dict = pickle.load(fp)\n",
    "else:\n",
    "    print(\"generate and save to file\")\n",
    "    valueq = Parallel(n_jobs=30)(delayed(short_compute_pagerank)(*tup) for tup in tqdm(keyq))\n",
    "\n",
    "# valueq = pool.starmap(\n",
    "#     func=short_compute_pagerank,\n",
    "#     iterable=tqdm(keyq),\n",
    "#     chunksize=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### big number of values to compute\n",
    "In total, there will be **21,250** jobs\n",
    "\n",
    "+ Number of survey time for each user: 5\n",
    "+ Number of observers: 34\n",
    "+ Number of parameters\n",
    "    - Pagerank damping factor: 5\n",
    "    - Beta alpha, beta: 5*5=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"res/pr_dict.pkl\", \"wb\") as fp:\n",
    "    dictq = dict(zip(keyq, [v[0] for v in valueq]))\n",
    "    pickle.dump(dictq, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "gcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
